{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Mixup.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"G7bg2ERJGjc4","colab_type":"code","outputId":"dac9c42d-81f8-4e35-cbe8-fb327089a987","executionInfo":{"status":"error","timestamp":1575736979186,"user_tz":420,"elapsed":923570,"user":{"displayName":"Prashant Jadhav","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBxwSu-o99QLa6W50GUEL3XE5-8n-m8u3eyptECJA=s64","userId":"12969679806480930958"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Mixup model on the cifar10 dataset\n","#We have refered to the code from below github link\n","#https://github.com/yu4u/mixup-generator\n","# This link contains the mixup generator code we used \n","#to augment data using mixup_generator and we have used it for our analysis\n","#Below is the licence copyright for mixup generator imported in this code\n","#MIT License\n","#Copyright (c) 2017 Yusuke Uchida\n","\n","#@author : Prashant Jadhav\n","\n","import sys\n","from matplotlib import pyplot\n","from keras.datasets import cifar10\n","from keras.utils import to_categorical\n","from keras.models import Sequential\n","from keras.layers import Conv2D\n","from keras.layers import MaxPooling2D\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.optimizers import SGD\n","from keras.regularizers import l2\n","from keras.preprocessing.image import ImageDataGenerator\n","import numpy as np\n","import sklearn.metrics as metrics\n","from sklearn.metrics import confusion_matrix\n","from mixup_generator import MixupGenerator #This particular loc is used from github link https://github.com/yu4u/mixup-generator usage section\n","import seaborn as sns\n","\n","# load train and test dataset\n","def load_dataset():\n","\t# load dataset\n","\t(train_X, train_Y), (test_X, test_Y1) = cifar10.load_data()\n","\t# one hot encode target values\n","\ttrain_Y = to_categorical(train_Y)\n","\ttest_Y = to_categorical(test_Y1)\n","\treturn train_X, train_Y, test_X, test_Y, test_Y1\n","\n","# scale pixels\n","def prep_pixels(train, test):\n","\t# convert from integers to floats\n","\ttraining_norm = train.astype('float32')\n","\ttesting_norm = test.astype('float32')\n","\t# normalize to range 0-1\n","\ttraining_norm = training_norm / 255.0\n","\ttesting_norm = testing_norm / 255.0\n","\t# return normalized images\n","\treturn training_norm, testing_norm\n","\n","# define cnn modez\n","def define_model():\n","\tmodel = Sequential()\n","\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001), input_shape=(32, 32, 3)))\n","\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n","\tmodel.add(MaxPooling2D((2, 2)))\n","\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n","\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n","\tmodel.add(MaxPooling2D((2, 2)))\n","\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n","\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', kernel_regularizer=l2(0.001)))\n","\tmodel.add(MaxPooling2D((2, 2)))\n","\tmodel.add(Flatten())\n","\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform', kernel_regularizer=l2(0.001)))\n","\tmodel.add(Dense(10, activation='softmax'))\n","\t# compile model\n","\topt = SGD(lr=0.001, momentum=0.9)\n","\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n","\t\n","\treturn model\n","\n","# plot diagnostic learning curves\n","def summarize_diagnostics(history):\n","\t# plot loss\n","\tpyplot.subplot(211)\n","\tpyplot.title('Cross Entropy Loss')\n","\tpyplot.plot(history.history['loss'], color='blue', label='train')\n","\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n","\t# plot accuracy\n","\tpyplot.subplot(212)\n","\tpyplot.title('Classification Accuracy')\n","\tpyplot.plot(history.history['acc'], color='blue', label='train')\n","\tpyplot.plot(history.history['val_acc'], color='orange', label='test')\n","\t# save plot to file\n","\tfilename = sys.argv[0].split('/')[-1]\n","\tpyplot.savefig(filename + '_plot.png')\n","\tpyplot.close()\n","\n","# run the test harness for evaluating a model\n","def run_test_harness():\n","\t# load dataset\n","\ttrain_X, train_Y, test_X, test_Y, test_Y1 = load_dataset()\n","\t# prepare pixel data\n","\ttrain_X, test_X = prep_pixels(train_X, test_X)\n","\t# define model\n","\tmodel = define_model()\n","\t# fit model\n","\t#history = model.fit(train_X, train_Y, epochs=100, batch_size=500, validation_data=(test_X, test_Y), verbose=1)\n","\tdatagen = ImageDataGenerator(\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    horizontal_flip=True)\n","\ttraining_generator = MixupGenerator(train_X, train_Y, batch_size=500, alpha=0.2, datagen=datagen)()\n","\thistory=model.fit_generator(generator=training_generator,\n","                        steps_per_epoch=500 ,\n","                        validation_data=(test_X, test_Y),\n","                        epochs=50, verbose=1)\n","\t#confusion matrix\n","\ty_pred_ohe = model.predict(test_X) \n","\ty_pred_labels = np.argmax(y_pred_ohe, axis=1) \n","\tconfusion_matrix = metrics.confusion_matrix(y_true=test_Y1, y_pred=y_pred_labels)\n","\tfigure = pyplot.figure(figsize=(8, 8))\n","\tsns.heatmap(confusion_matrix, annot=False,cmap=pyplot.cm.Blues)\n","\tpyplot.tight_layout()\n","\tpyplot.ylabel('True label')\n","\tpyplot.xlabel('Predicted label')\n","\tpyplot.imshow(confusion_matrix)\n","\t# evaluate model\n","\t_, acc = model.evaluate(test_X, test_Y, verbose=0)\n","\tprint('> %.3f' % (acc * 100.0))\n","\t# learning curves\n","\t#summarize_diagnostics(history)\n","\n","# entry point, run the test harness\n","run_test_harness()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 11s 0us/step\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Epoch 1/50\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","500/500 [==============================] - 165s 331ms/step - loss: 3.0678 - acc: 0.3268 - val_loss: 2.6855 - val_acc: 0.4448\n","Epoch 2/50\n","500/500 [==============================] - 157s 313ms/step - loss: 2.7882 - acc: 0.4374 - val_loss: 2.5043 - val_acc: 0.5049\n","Epoch 3/50\n","500/500 [==============================] - 156s 312ms/step - loss: 2.6854 - acc: 0.4753 - val_loss: 2.3907 - val_acc: 0.5419\n","Epoch 4/50\n","500/500 [==============================] - 157s 313ms/step - loss: 2.5983 - acc: 0.5064 - val_loss: 2.2887 - val_acc: 0.5779\n","Epoch 5/50\n","500/500 [==============================] - 157s 313ms/step - loss: 2.5276 - acc: 0.5306 - val_loss: 2.2700 - val_acc: 0.5777\n","Epoch 6/50\n","500/500 [==============================] - 157s 314ms/step - loss: 2.4672 - acc: 0.5489 - val_loss: 2.1967 - val_acc: 0.5945\n","Epoch 7/50\n","500/500 [==============================] - 154s 308ms/step - loss: 2.4087 - acc: 0.5689 - val_loss: 2.0857 - val_acc: 0.6318\n","Epoch 8/50\n","500/500 [==============================] - 150s 301ms/step - loss: 2.3581 - acc: 0.5822 - val_loss: 2.0420 - val_acc: 0.6424\n","Epoch 9/50\n","500/500 [==============================] - 150s 300ms/step - loss: 2.3135 - acc: 0.5968 - val_loss: 1.9792 - val_acc: 0.6599\n","Epoch 10/50\n","500/500 [==============================] - 148s 297ms/step - loss: 2.2716 - acc: 0.6065 - val_loss: 1.9390 - val_acc: 0.6679\n","Epoch 11/50\n","500/500 [==============================] - 162s 324ms/step - loss: 2.2285 - acc: 0.6194 - val_loss: 1.9167 - val_acc: 0.6689\n","Epoch 12/50\n","500/500 [==============================] - 147s 295ms/step - loss: 2.1863 - acc: 0.6309 - val_loss: 1.8607 - val_acc: 0.6854\n","Epoch 13/50\n","500/500 [==============================] - 165s 329ms/step - loss: 2.1513 - acc: 0.6399 - val_loss: 1.8458 - val_acc: 0.6881\n","Epoch 14/50\n","500/500 [==============================] - 153s 306ms/step - loss: 2.1130 - acc: 0.6490 - val_loss: 1.8010 - val_acc: 0.6975\n","Epoch 15/50\n","500/500 [==============================] - 166s 332ms/step - loss: 2.0830 - acc: 0.6557 - val_loss: 1.8007 - val_acc: 0.6899\n","Epoch 16/50\n","500/500 [==============================] - 150s 301ms/step - loss: 2.0467 - acc: 0.6657 - val_loss: 1.7189 - val_acc: 0.7162\n","Epoch 17/50\n","500/500 [==============================] - 165s 330ms/step - loss: 2.0212 - acc: 0.6718 - val_loss: 1.7212 - val_acc: 0.7091\n","Epoch 18/50\n","500/500 [==============================] - 151s 302ms/step - loss: 1.9920 - acc: 0.6786 - val_loss: 1.6544 - val_acc: 0.7302\n","Epoch 19/50\n","500/500 [==============================] - 149s 298ms/step - loss: 1.9641 - acc: 0.6835 - val_loss: 1.6618 - val_acc: 0.7203\n","Epoch 20/50\n","500/500 [==============================] - 150s 299ms/step - loss: 1.9368 - acc: 0.6895 - val_loss: 1.6086 - val_acc: 0.7375\n","Epoch 21/50\n","500/500 [==============================] - 151s 302ms/step - loss: 1.9101 - acc: 0.6956 - val_loss: 1.6057 - val_acc: 0.7281\n","Epoch 22/50\n","500/500 [==============================] - 148s 297ms/step - loss: 1.8841 - acc: 0.7009 - val_loss: 1.5532 - val_acc: 0.7439\n","Epoch 23/50\n","500/500 [==============================] - 168s 336ms/step - loss: 1.8603 - acc: 0.7066 - val_loss: 1.5509 - val_acc: 0.7442\n","Epoch 24/50\n","500/500 [==============================] - 148s 296ms/step - loss: 1.8416 - acc: 0.7071 - val_loss: 1.5549 - val_acc: 0.7370\n","Epoch 25/50\n","500/500 [==============================] - 149s 297ms/step - loss: 1.8187 - acc: 0.7123 - val_loss: 1.5389 - val_acc: 0.7369\n","Epoch 26/50\n","500/500 [==============================] - 149s 298ms/step - loss: 1.7937 - acc: 0.7186 - val_loss: 1.4555 - val_acc: 0.7623\n","Epoch 27/50\n","500/500 [==============================] - 150s 300ms/step - loss: 1.7748 - acc: 0.7211 - val_loss: 1.4686 - val_acc: 0.7519\n","Epoch 28/50\n","500/500 [==============================] - 150s 301ms/step - loss: 1.7532 - acc: 0.7262 - val_loss: 1.4299 - val_acc: 0.7668\n","Epoch 29/50\n","500/500 [==============================] - 150s 299ms/step - loss: 1.7342 - acc: 0.7290 - val_loss: 1.4056 - val_acc: 0.7677\n","Epoch 30/50\n","500/500 [==============================] - 148s 296ms/step - loss: 1.7132 - acc: 0.7336 - val_loss: 1.4049 - val_acc: 0.7655\n","Epoch 31/50\n","500/500 [==============================] - 147s 295ms/step - loss: 1.6935 - acc: 0.7375 - val_loss: 1.3905 - val_acc: 0.7651\n","Epoch 32/50\n","500/500 [==============================] - 147s 294ms/step - loss: 1.6765 - acc: 0.7386 - val_loss: 1.3724 - val_acc: 0.7696\n","Epoch 33/50\n","500/500 [==============================] - 147s 293ms/step - loss: 1.6604 - acc: 0.7414 - val_loss: 1.3916 - val_acc: 0.7595\n","Epoch 34/50\n","500/500 [==============================] - 145s 290ms/step - loss: 1.6429 - acc: 0.7451 - val_loss: 1.3571 - val_acc: 0.7658\n","Epoch 35/50\n","500/500 [==============================] - 146s 292ms/step - loss: 1.6299 - acc: 0.7460 - val_loss: 1.3317 - val_acc: 0.7729\n","Epoch 36/50\n","500/500 [==============================] - 146s 292ms/step - loss: 1.6115 - acc: 0.7495 - val_loss: 1.3053 - val_acc: 0.7787\n","Epoch 37/50\n","500/500 [==============================] - 147s 294ms/step - loss: 1.5989 - acc: 0.7512 - val_loss: 1.2892 - val_acc: 0.7795\n","Epoch 38/50\n","500/500 [==============================] - 144s 288ms/step - loss: 1.5801 - acc: 0.7554 - val_loss: 1.3011 - val_acc: 0.7736\n","Epoch 39/50\n","500/500 [==============================] - 146s 291ms/step - loss: 1.5681 - acc: 0.7566 - val_loss: 1.2579 - val_acc: 0.7874\n","Epoch 40/50\n","500/500 [==============================] - 150s 300ms/step - loss: 1.5535 - acc: 0.7579 - val_loss: 1.2633 - val_acc: 0.7809\n","Epoch 41/50\n","500/500 [==============================] - 147s 294ms/step - loss: 1.5402 - acc: 0.7604 - val_loss: 1.2362 - val_acc: 0.7879\n","Epoch 42/50\n","500/500 [==============================] - 152s 303ms/step - loss: 1.5253 - acc: 0.7625 - val_loss: 1.2261 - val_acc: 0.7858\n","Epoch 43/50\n","500/500 [==============================] - 148s 296ms/step - loss: 1.5083 - acc: 0.7667 - val_loss: 1.2411 - val_acc: 0.7779\n","Epoch 44/50\n","500/500 [==============================] - 148s 296ms/step - loss: 1.4990 - acc: 0.7669 - val_loss: 1.1821 - val_acc: 0.7960\n","Epoch 45/50\n","369/500 [=====================>........] - ETA: 38s - loss: 1.4897 - acc: 0.7692"],"name":"stdout"}]}]}